{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBOIK2cqwn-r"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
        "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72y_x_kUwn_D"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLbyFOAUwn_N"
      },
      "outputs": [],
      "source": [
        "PROJECT_DIR = '/content/drive/MyDrive/Colab Notebooks/teachable-gradio'\n",
        "PROJECT_NAME = 'smp5_hanaca'\n",
        "TEACHABLE_MODEL_DIR = f'{PROJECT_DIR}/{PROJECT_NAME}/converted_keras'\n",
        "TEACHABLE_TRAIN_DIR = f'{PROJECT_DIR}/{PROJECT_NAME}/train'\n",
        "TEACHABLE_TEST_DIR = f'{PROJECT_DIR}/{PROJECT_NAME}/test'\n",
        "SHAPE = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1IzAGPewn_R"
      },
      "outputs": [],
      "source": [
        "# load the model and label\n",
        "model = load_model(f\"{TEACHABLE_MODEL_DIR}/keras_model.h5\", compile=False)\n",
        "class_names = open(f\"{TEACHABLE_MODEL_DIR}/labels.txt\", \"r\").readlines()\n",
        "class_names = [cn.replace('\\n', '') for cn in class_names]\n",
        "\n",
        "\n",
        "def pre_process_image(image):\n",
        "    # resizing the image to be at least 224x224 and then cropping from the center\n",
        "    image = ImageOps.fit(image, SHAPE, Image.LANCZOS)\n",
        "\n",
        "    # turn the image into a numpy array\n",
        "    image_array = np.asarray(image)\n",
        "\n",
        "    # normalize the image\n",
        "    image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
        "\n",
        "    # reshape the image to batch format\n",
        "    image_array = image_array.reshape((-1, SHAPE[0], SHAPE[1], 3))\n",
        "\n",
        "    return image_array\n",
        "\n",
        "\n",
        "def classify_image(image):\n",
        "    image = pre_process_image(image)\n",
        "    prediction = model.predict(image)\n",
        "    confidences = {class_names[i]: float(prediction[0][i]) for i in range(len(class_names))}\n",
        "    return confidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1IhQEHNwoA4"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_on_dataset(dataset_dir):\n",
        "    true_labels, predicted_labels, class_names_readed = predict_dataset_dir(dataset_dir)\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "    report = classification_report(true_labels, predicted_labels, target_names=class_names_readed)\n",
        "    return cm, report, class_names_readed\n",
        "\n",
        "def predict_dataset_dir(dataset_dir):\n",
        "    # initiate empty list\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    class_names_readed = []\n",
        "\n",
        "    # get and sort folders\n",
        "    listdir = np.array(os.listdir(dataset_dir))\n",
        "    class_names_index = [int(cn.split(' ')[0]) for cn in listdir]\n",
        "    idx = np.argsort(class_names_index)\n",
        "    listdir = listdir[idx]\n",
        "\n",
        "    # test images on folders\n",
        "    for class_name in listdir:\n",
        "        class_dir = os.path.join(dataset_dir, class_name)\n",
        "        for image_name in os.listdir(class_dir)[:2]:\n",
        "            try:\n",
        "              image_path = os.path.join(class_dir, image_name)\n",
        "              image = Image.open(image_path)\n",
        "              true_class_idx = class_names.index(class_name)\n",
        "              image = pre_process_image(image)\n",
        "            except:\n",
        "              continue\n",
        "            prediction = model.predict(image, verbose=0)\n",
        "            predicted_class_idx = np.argmax(prediction)\n",
        "\n",
        "            true_labels.append(true_class_idx)\n",
        "            predicted_labels.append(predicted_class_idx)\n",
        "            if class_name not in class_names_readed:\n",
        "              class_names_readed.append(class_name)\n",
        "\n",
        "    # fix numbering start from zero\n",
        "    true_labels = np.array(true_labels) - 1\n",
        "    predicted_labels = np.array(predicted_labels) - 1\n",
        "    return true_labels, predicted_labels, class_names_readed\n",
        "\n",
        "\n",
        "# Evaluate on the training set\n",
        "train_cm, train_report, train_class_names_readed = evaluate_model_on_dataset(TEACHABLE_TRAIN_DIR)\n",
        "print(\"Training Set Confusion Matrix:\")\n",
        "print(train_cm)\n",
        "print(\"Training Set Classification Report:\")\n",
        "print(train_report)\n",
        "\n",
        "# # Evaluate on the validation/test set\n",
        "# val_cm, val_report, val_class_names_readed = evaluate_model_on_dataset(TEACHABLE_TEST_DIR)\n",
        "# print(\"Validation Set Confusion Matrix:\")\n",
        "# print(val_cm)\n",
        "# print(\"Validation Set Classification Report:\")\n",
        "# print(val_report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vkgsDKKqTcVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "id": "y-2IpUWwwIY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report"
      ],
      "metadata": {
        "id": "CcLAQC7PwJgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(class_names_readed)"
      ],
      "metadata": {
        "id": "uxYj0knzwrDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(class_names_readed)"
      ],
      "metadata": {
        "id": "Q5zzuxmKxTGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels"
      ],
      "metadata": {
        "id": "ieM6yo3kyX31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dOr38NnSyYY1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}