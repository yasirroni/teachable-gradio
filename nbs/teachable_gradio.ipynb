{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1p0NqFHwn-S"
      },
      "outputs": [],
      "source": [
        "!pip install -qq gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBOIK2cqwn-r"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
        "from PIL import Image, ImageOps  # Install pillow instead of PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72y_x_kUwn_D"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    # support save files in drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLbyFOAUwn_N"
      },
      "outputs": [],
      "source": [
        "PROJECT_DIR = '/content/drive/MyDrive/Colab Notebooks/teachable-gradio'\n",
        "PROJECT_NAME = 'sample_project'\n",
        "TEACHABLE_MODEL_DIR = f'{PROJECT_DIR}/{PROJECT_NAME}/converted_keras'\n",
        "SHAPE = (224, 224)\n",
        "\n",
        "# NOTE:\n",
        "#   Teachable Website: https://teachablemachine.withgoogle.com/train/image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1IzAGPewn_R"
      },
      "outputs": [],
      "source": [
        "# load the model and label\n",
        "model = load_model(f\"{TEACHABLE_MODEL_DIR}/keras_model.h5\", compile=False)\n",
        "class_names = open(f\"{TEACHABLE_MODEL_DIR}/labels.txt\", \"r\").readlines()\n",
        "\n",
        "\n",
        "def pre_process_image(image):\n",
        "    # resizing the image to be at least 224x224 and then cropping from the center\n",
        "    image = ImageOps.fit(image, SHAPE, Image.LANCZOS)\n",
        "\n",
        "    # turn the image into a numpy array\n",
        "    image_array = np.asarray(image)\n",
        "\n",
        "    # normalize the image\n",
        "    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
        "\n",
        "    # reshape the image to batch format\n",
        "    reshaped_image_array = normalized_image_array.reshape((-1, SHAPE[0], SHAPE[1], 3))\n",
        "\n",
        "    return reshaped_image_array\n",
        "\n",
        "\n",
        "def classify_image(image):\n",
        "    image = pre_process_image(image)\n",
        "    prediction = model.predict(image)\n",
        "    confidences = {class_names[i]: float(prediction[0][i]) for i in range(len(class_names))}\n",
        "    return confidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1IhQEHNwoA4"
      },
      "outputs": [],
      "source": [
        "gr.Interface(fn=classify_image,\n",
        "             inputs=gr.Image(shape=SHAPE, type='pil'),\n",
        "             outputs=gr.Label(num_top_classes=2)).launch(quiet=True)\n",
        "\n",
        "# NOTE:\n",
        "#   use .launch(debug=True) to debug your gradio interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MavwXLrjwoBR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}